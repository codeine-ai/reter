"""
Performance tests for RETE network with large ontologies
Tests parsing, reasoning, and query performance with increasing scale
"""

import sys
import os
# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'rete_cpp'))

import time
import pytest
from reter_core import owl_rete_cpp

# Mark all tests in this module as slow
pytestmark = pytest.mark.slow


def format_time(seconds):
    """Format time in appropriate units"""
    if seconds < 0.001:
        return f"{seconds * 1000000:.2f} ¬µs"
    elif seconds < 1:
        return f"{seconds * 1000:.2f} ms"
    else:
        return f"{seconds:.2f} s"


def test_small_ontology_baseline():
    """Baseline test with small ontology (10 classes, 10 individuals)"""
    print("\n" + "=" * 80)
    print("PERFORMANCE TEST: Small Ontology Baseline (10 classes, 10 individuals)")
    print("=" * 80)

    network = owl_rete_cpp.ReteNetwork()

    # Generate small ontology (simplified, no comments)
    ontology = """
Animal ‚äë·ë¶ Thing
Mammal ‚äë·ë¶ Animal
Bird ‚äë·ë¶ Animal
Dog ‚äë·ë¶ Mammal
Cat ‚äë·ë¶ Mammal
Eagle ‚äë·ë¶ Bird
Sparrow ‚äë·ë¶ Bird
Pet ‚äë·ë¶ Thing
DogÔºàFidoÔºâ
CatÔºàWhiskersÔºâ
EagleÔºàBaldyÔºâ
    """

    # Measure parsing (C++ parser integrated in RETE)
    start = time.perf_counter()
    wme_count = network.load_ontology_from_string(ontology)
    parse_time = time.perf_counter() - start

    # Reasoning is incremental in RETE (happens during parsing)
    reason_time = 0.0

    # Get stats
    total_facts = network.fact_count()

    print(f"\nüìä Results:")
    print(f"  Parsing time:      {format_time(parse_time)}")
    print(f"  Reasoning time:    {format_time(reason_time)} (incremental)")
    print(f"  Total time:        {format_time(parse_time + reason_time)}")
    print(f"  WMEs added:        {wme_count}")
    print(f"  Total facts:       {total_facts}")
    print(f"  Parse rate:        {wme_count / parse_time if parse_time > 0 else 0:.0f} WMEs/sec")

    print("\n‚úì Baseline test completed")


def test_medium_ontology_hierarchy():
    """Test with medium ontology (30 classes, 60 individuals)"""
    print("\n" + "=" * 80)
    print("PERFORMANCE TEST: Medium Ontology (30 classes, 60 individuals)")
    print("=" * 80)

    network = owl_rete_cpp.ReteNetwork()

    # Generate medium-sized class hierarchy
    classes = []

    # Top-level categories
    categories = ["Living", "NonLiving", "Abstract"]
    for cat in categories:
        classes.append(f"{cat} ‚äë·ë¶ Thing")

    # Second level (10 per category)
    for i, cat in enumerate(categories):
        for j in range(10):
            cls_name = f"{cat}{j}"
            classes.append(f"{cls_name} ‚äë·ë¶ {cat}")

    # Individuals (2 per leaf class)
    individuals = []
    for i, cat in enumerate(categories):
        for j in range(10):
            cls_name = f"{cat}{j}"
            individuals.append(f"{cls_name}Ôºà{cls_name}aÔºâ")
            individuals.append(f"{cls_name}Ôºà{cls_name}bÔºâ")

    ontology = "\n".join(classes + individuals)

    # Measure parsing (C++ parser integrated in RETE)
    start = time.perf_counter()
    wme_count = network.load_ontology_from_string(ontology)
    parse_time = time.perf_counter() - start

    # Reasoning is incremental
    reason_time = 0.0

    # Get stats
    total_facts = network.fact_count()

    print(f"\nüìä Results:")
    print(f"  Parsing time:      {format_time(parse_time)}")
    print(f"  Reasoning time:    {format_time(reason_time)} (incremental)")
    print(f"  Total time:        {format_time(parse_time + reason_time)}")
    print(f"  WMEs added:        {wme_count}")
    print(f"  Total facts:       {total_facts}")
    print(f"  Parse rate:        {wme_count / parse_time if parse_time > 0 else 0:.0f} WMEs/sec")

    print("\n‚úì Medium ontology test completed")


def test_large_ontology_deep_hierarchy():
    """Test with large ontology with deep hierarchy (60 classes, 100 individuals)"""
    print("\n" + "=" * 80)
    print("PERFORMANCE TEST: Large Ontology (60 classes, 100 individuals)")
    print("=" * 80)

    network = owl_rete_cpp.ReteNetwork()

    # Generate deep hierarchy
    ontology_parts = []

    # Create 5 main branches, each with 12 classes in a chain
    for branch in range(5):
        branch_name = f"Br{branch}"
        ontology_parts.append(f"{branch_name}0 ‚äë·ë¶ Thing")

        # Create chain of 11 classes
        for depth in range(1, 12):
            parent = f"{branch_name}{depth-1}"
            child = f"{branch_name}{depth}"
            ontology_parts.append(f"{child} ‚äë·ë¶ {parent}")

        # Add individuals to leaf classes (20 per branch)
        leaf_class = f"{branch_name}11"
        for i in range(20):
            ontology_parts.append(f"{leaf_class}Ôºà{branch_name}i{i}Ôºâ")

    ontology = "\n".join(ontology_parts)

    # Measure parsing (C++ parser integrated in RETE)
    start = time.perf_counter()
    wme_count = network.load_ontology_from_string(ontology)
    parse_time = time.perf_counter() - start

    # Reasoning is incremental
    reason_time = 0.0

    # Get stats
    total_facts = network.fact_count()

    print(f"\nüìä Results:")
    print(f"  Parsing time:      {format_time(parse_time)}")
    print(f"  Reasoning time:    {format_time(reason_time)} (incremental)")
    print(f"  Total time:        {format_time(parse_time + reason_time)}")
    print(f"  WMEs added:        {wme_count}")
    print(f"  Total facts:       {total_facts}")
    print(f"  Parse rate:        {wme_count / parse_time if parse_time > 0 else 0:.0f} WMEs/sec")

    print("\n‚úì Large ontology test completed")


def test_property_intensive_ontology():
    """Test with property-intensive ontology (many relations and property chains)"""
    print("\n" + "=" * 80)
    print("PERFORMANCE TEST: Property-Intensive Ontology (100 properties, 200 relations)")
    print("=" * 80)

    network = owl_rete_cpp.ReteNetwork()

    ontology_parts = []

    # Create base classes
    ontology_parts.append("Person ‚äë·ë¶ Thing")
    ontology_parts.append("Organization ‚äë·ë¶ Thing")
    ontology_parts.append("Location ‚äë·ë¶ Thing")

    # Skip problematic property subsumptions that cause exponential blowup
    # These axioms trigger exponential reasoning with many role assertions:
    # ontology_parts.append("hasParent ‚äë·ë¶ ‚ä§ ‚äì ‚ä§")
    # ontology_parts.append("knows ‚äë·ë¶ ‚ä§ ‚äì ‚ä§")

    # Skip transitive property declarations (also cause exponential blowup)
    # for i in range(5):
    #     prop = f"related{i}"
    #     ontology_parts.append(f"{prop} ‚äë·ë¶ ‚ä§ ‚äì ‚ä§")

    # Create 50 individuals
    individuals = []
    for i in range(50):
        individuals.append(f"PersonÔºàperson{i}Ôºâ")

    # Create dense relationship network (200 relations)
    relations = []
    for i in range(40):
        for j in range(5):
            if i + j + 1 < 50:
                relations.append(f"hasParentÔºàperson{i}Ôºåperson{i + j + 1}Ôºâ")

    ontology = "\n".join(ontology_parts + individuals + relations)

    # Measure parsing (C++ parser integrated in RETE)
    start = time.perf_counter()
    wme_count = network.load_ontology_from_string(ontology)
    parse_time = time.perf_counter() - start

    # Reasoning is incremental
    reason_time = 0.0

    # Get stats
    total_facts = network.fact_count()

    print(f"\nüìä Results:")
    print(f"  Parsing time:      {format_time(parse_time)}")
    print(f"  Reasoning time:    {format_time(reason_time)} (incremental)")
    print(f"  Total time:        {format_time(parse_time + reason_time)}")
    print(f"  WMEs added:        {wme_count}")
    print(f"  Total facts:       {total_facts}")
    print(f"  Parse rate:        {wme_count / parse_time if parse_time > 0 else 0:.0f} WMEs/sec")

    print("\n‚úì Property-intensive test completed")


def test_complex_restrictions_ontology():
    """Test with complex class restrictions (intersections, unions, existentials)"""
    print("\n" + "=" * 80)
    print("PERFORMANCE TEST: Complex Restrictions (100 restriction classes)")
    print("=" * 80)

    network = owl_rete_cpp.ReteNetwork()

    ontology_parts = []

    # Base classes
    base_classes = ["Animal", "Plant", "Mineral", "Food", "Tool"]
    for cls in base_classes:
        ontology_parts.append(f"{cls} ‚äë·ë¶ Thing")

    # Create complex intersection classes
    for i in range(20):
        cls1 = base_classes[i % len(base_classes)]
        cls2 = base_classes[(i + 1) % len(base_classes)]
        ontology_parts.append(f"Complex{i} ‚â°·ë¶ {cls1} ‚äì {cls2}")

    # Create union classes
    for i in range(20):
        cls1 = base_classes[i % len(base_classes)]
        cls2 = base_classes[(i + 2) % len(base_classes)]
        ontology_parts.append(f"Union{i} ‚â°·ë¶ {cls1} ‚äî {cls2}")

    # Skip property subsumption that causes exponential blowup
    # ontology_parts.append("hasPart ‚äë·ë¶ ‚ä§ ‚äì ‚ä§")

    # Create existential restrictions (without the property subsumption)
    for i in range(20):
        cls = base_classes[i % len(base_classes)]
        ontology_parts.append(f"HasPart{i} ‚â°·ë¶ ‚àÉhasPart‚Ä§{cls}")

    # Create universal restrictions
    for i in range(20):
        cls = base_classes[i % len(base_classes)]
        ontology_parts.append(f"OnlyHas{i} ‚â°·ë¶ ‚àÄhasPart‚Ä§{cls}")

    # Create cardinality restrictions
    for i in range(10):
        ontology_parts.append(f"MinCard{i} ‚â°·ë¶ ‚â•{i + 1} hasPart‚Ä§Thing")
        ontology_parts.append(f"MaxCard{i} ‚â°·ë¶ ‚â§{i + 1} hasPart‚Ä§Thing")

    # Add individuals and assertions
    for i in range(50):
        cls = base_classes[i % len(base_classes)]
        ontology_parts.append(f"{cls}Ôºàentity{i}Ôºâ")

    ontology = "\n".join(ontology_parts)

    # Measure parsing (C++ parser integrated in RETE)
    start = time.perf_counter()
    wme_count = network.load_ontology_from_string(ontology)
    parse_time = time.perf_counter() - start

    # Reasoning is incremental
    reason_time = 0.0

    # Get stats
    total_facts = network.fact_count()

    print(f"\nüìä Results:")
    print(f"  Parsing time:      {format_time(parse_time)}")
    print(f"  Reasoning time:    {format_time(reason_time)} (incremental)")
    print(f"  Total time:        {format_time(parse_time + reason_time)}")
    print(f"  WMEs added:        {wme_count}")
    print(f"  Total facts:       {total_facts}")
    print(f"  Parse rate:        {wme_count / parse_time if parse_time > 0 else 0:.0f} WMEs/sec")

    print("\n‚úì Complex restrictions test completed")


def test_scaling_analysis():
    """Scaling analysis: measure how performance scales with ontology size"""
    print("\n" + "=" * 80)
    print("PERFORMANCE TEST: Scaling Analysis")
    print("=" * 80)

    sizes = [10, 25, 50, 75, 100]
    results = []

    for size in sizes:
        network = owl_rete_cpp.ReteNetwork()

        # Generate ontology with 'size' classes and 2*size individuals
        ontology_parts = []

        # Create linear hierarchy
        ontology_parts.append("Root ‚äë·ë¶ Thing")
        for i in range(1, size):
            ontology_parts.append(f"Class{i} ‚äë·ë¶ Class{i-1}" if i > 1 else f"Class{i} ‚äë·ë¶ Root")

        # Add individuals
        for i in range(size * 2):
            cls_idx = i % size
            cls_name = f"Class{cls_idx}" if cls_idx > 0 else "Root"
            ontology_parts.append(f"{cls_name}Ôºàind{i}Ôºâ")

        ontology = "\n".join(ontology_parts)

        # Measure parsing (C++ parser integrated in RETE)
        start = time.perf_counter()
        wme_count = network.load_ontology_from_string(ontology)
        parse_time = time.perf_counter() - start

        # Reasoning is incremental
        reason_time = 0.0

        total_facts = network.fact_count()

        results.append({
            'size': size,
            'parse_time': parse_time,
            'reason_time': reason_time,
            'total_time': parse_time + reason_time,
            'wme_count': wme_count,
            'total_facts': total_facts
        })

        print(f"\n  Size {size:3d}: Parse={format_time(parse_time):>10s}  "
              f"Reason={format_time(reason_time):>10s} (incremental)  "
              f"Total={format_time(parse_time + reason_time):>10s}  "
              f"Facts={total_facts:>5d}")

    # Print summary table
    print("\n" + "-" * 80)
    print("Scaling Summary:")
    print("-" * 80)
    print(f"{'Size':>6} | {'Parse Time':>12} | {'Reason Time':>12} | {'Total Time':>12} | {'Facts':>6}")
    print("-" * 80)
    for r in results:
        print(f"{r['size']:>6} | {format_time(r['parse_time']):>12} | "
              f"{format_time(r['reason_time']):>12} | {format_time(r['total_time']):>12} | "
              f"{r['total_facts']:>6}")
    print("-" * 80)

    print("\n‚úì Scaling analysis completed")


if __name__ == '__main__':
    print("\n" + "=" * 80)
    print("RETE NETWORK PERFORMANCE TEST SUITE")
    print("=" * 80)

    # Run all performance tests
    print("Test 1...")
    test_small_ontology_baseline()
    print("Test 1 completed!\n")

    print("Test 2...")
    test_medium_ontology_hierarchy()
    print("Test 2 completed!\n")

    print("Test 3...")
    test_large_ontology_deep_hierarchy()
    print("Test 3 completed!\n")

    print("Test 4...")
    test_property_intensive_ontology()
    print("Test 4 completed!\n")

    print("Test 5...")
    test_complex_restrictions_ontology()
    print("Test 5 completed!\n")

    print("Test 6...")
    test_scaling_analysis()
    print("Test 6 completed!\n")

    print("\n" + "=" * 80)
    print("ALL PERFORMANCE TESTS COMPLETED")
    print("=" * 80)
